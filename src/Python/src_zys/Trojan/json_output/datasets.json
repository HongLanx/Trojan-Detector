"Module(body=[ImportFrom(module='trojanzoo.configs', names=[alias(name='config')], level=0), ImportFrom(module='trojanzoo.environ', names=[alias(name='env')], level=0), ImportFrom(module='trojanzoo.utils.data', names=[alias(name='get_class_subset'), alias(name='split_dataset')], level=0), ImportFrom(module='trojanzoo.utils.module', names=[alias(name='BasicObject'), alias(name='get_name')], level=0), ImportFrom(module='trojanzoo.utils.output', names=[alias(name='ansi')], level=0), Import(names=[alias(name='torch')]), Import(names=[alias(name='numpy', asname='np')]), Import(names=[alias(name='functools')]), Import(names=[alias(name='os')]), ImportFrom(module='abc', names=[alias(name='ABC'), alias(name='abstractmethod')], level=0), ImportFrom(module='typing', names=[alias(name='TYPE_CHECKING')], level=0), ImportFrom(module='typing', names=[alias(name='Iterable')], level=0), ImportFrom(module='trojanzoo.configs', names=[alias(name='Config')], level=0), Import(names=[alias(name='argparse')]), ImportFrom(module='collections.abc', names=[alias(name='Callable')], level=0), If(test=Name(id='TYPE_CHECKING', ctx=Load()), body=[Import(names=[alias(name='torch.utils.data')])], orelse=[]), ClassDef(name='Dataset', bases=[Name(id='ABC', ctx=Load()), Name(id='BasicObject', ctx=Load())], keywords=[], body=[Expr(value=Constant(value=\"\\n    | An abstract class representing a dataset.\\n    | It inherits :class:`trojanzoo.utils.module.BasicObject`.\\n\\n    Note:\\n        This is the implementation of dataset.\\n        For users, please use :func:`create` instead, which is more user-friendly.\\n\\n    Args:\\n        batch_size (int): Batch size of training set\\n            (negative number means batch size for each gpu).\\n            Defaults to ``100``.\\n        valid_batch_size (int): Batch size of validation set.\\n            Defaults to ``100``.\\n        folder_path (str): Folder path to store dataset.\\n            Defaults to ``None``.\\n\\n            Note:\\n                :attr:`folder_path` is usually\\n                ``'{data_dir}/{data_type}/{name}'``,\\n                which is claimed as the default value of :func:`create()`.\\n        download (bool): Download dataset if not exist. Defaults to ``False``.\\n        split_ratio (float):\\n            | Split training set for training and validation\\n              if :attr:`valid_set` is ``False``.\\n            | The ratio stands for\\n              :math:`\\\\frac{\\\\text{\\\\# training\\\\ subset}}{\\\\text{\\\\# total\\\\ training\\\\ set}}`.\\n            | Defaults to ``0.8``.\\n        num_workers (int): Used in :meth:`get_dataloader()`.\\n            Defaults to ``4``.\\n        loss_weights (bool | np.ndarray | torch.Tensor):\\n            | The loss weights w.r.t. each class.\\n            | if :any:`numpy.ndarray` or :any:`torch.Tensor`,\\n              directly set as :attr:`loss_weights` (cpu tensor).\\n            | if ``True``, set :attr:`loss_weights` as :meth:`get_loss_weights()`;\\n            | if ``False``, set :attr:`loss_weights` as ``None``.\\n        **kwargs: Any keyword argument (unused).\\n\\n    Attributes:\\n        name (str): Dataset Name. (need overriding)\\n        loader(dict[str, ~torch.utils.data.DataLoader]):\\n            | Preset dataloader for users at dataset initialization.\\n            | It contains ``'train'`` and ``'valid'`` loaders.\\n        batch_size (int): Batch size of training set (always positive).\\n            Defaults to ``100``.\\n        valid_batch_size (int): Batch size of validation set.\\n            Defaults to ``100``.\\n        num_classes (int): Number of classes. (need overriding)\\n        folder_path (str): Folder path to store dataset.\\n            Defaults to ``None``.\\n\\n        data_type (str): Data type (e.g., ``'image'``). (need overriding)\\n        label_names (list[int]): Number of classes. (optional)\\n        valid_set (bool): Whether having a native validation set.\\n            Defaults to ``True``.\\n        split_ratio (float):\\n            | Split training set for training and validation\\n              if :attr:`valid_set` is ``False``.\\n            | The ratio stands for\\n              :math:`\\\\frac{\\\\text{\\\\# training\\\\ subset}}{\\\\text{\\\\# total\\\\ training\\\\ set}}`.\\n            | Defaults to ``0.8``.\\n        loss_weights (torch.Tensor | None): The loss weights w.r.t. each class.\\n        num_workers (int): Used in :meth:`get_dataloader()`.\\n            Defaults to ``4``.\\n        collate_fn (~collections.abc.Callable | None):\\n            Used in :meth:`get_dataloader()`.\\n            Defaults to ``None``.\\n    \")), Assign(targets=[Name(id='name', ctx=Store())], value=Constant(value='dataset')), AnnAssign(target=Name(id='data_type', ctx=Store()), annotation=Name(id='str', ctx=Load()), value=Constant(value=None), simple=1), AnnAssign(target=Name(id='num_classes', ctx=Store()), annotation=Name(id='int', ctx=Load()), value=Constant(value=None), simple=1), AnnAssign(target=Name(id='label_names', ctx=Store()), annotation=Subscript(value=Name(id='list', ctx=Load()), slice=Name(id='int', ctx=Load()), ctx=Load()), value=Constant(value=None), simple=1), Assign(targets=[Name(id='valid_set', ctx=Store())], value=Constant(value=True)), FunctionDef(name='add_argument', args=arguments(posonlyargs=[], args=[arg(arg='cls'), arg(arg='group', annotation=Attribute(value=Name(id='argparse', ctx=Load()), attr='_ArgumentGroup', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='Add dataset arguments to argument parser group.\\n        View source to see specific arguments.\\n\\n        Note:\\n            This is the implementation of adding arguments.\\n            The concrete dataset class may override this method to add more arguments.\\n            For users, please use :func:`add_argument()` instead, which is more user-friendly.\\n        ')), Expr(value=Call(func=Attribute(value=Name(id='group', ctx=Load()), attr='add_argument', ctx=Load()), args=[Constant(value='-d'), Constant(value='--dataset')], keywords=[keyword(arg='dest', value=Constant(value='dataset_name')), keyword(arg='help', value=Constant(value='dataset name (lowercase)'))])), Expr(value=Call(func=Attribute(value=Name(id='group', ctx=Load()), attr='add_argument', ctx=Load()), args=[Constant(value='--batch_size')], keywords=[keyword(arg='type', value=Name(id='int', ctx=Load())), keyword(arg='help', value=Constant(value='batch size (negative number means batch_size for each gpu)'))])), Expr(value=Call(func=Attribute(value=Name(id='group', ctx=Load()), attr='add_argument', ctx=Load()), args=[Constant(value='--valid_batch_size')], keywords=[keyword(arg='type', value=Name(id='int', ctx=Load())), keyword(arg='help', value=Constant(value='valid batch size'))])), Expr(value=Call(func=Attribute(value=Name(id='group', ctx=Load()), attr='add_argument', ctx=Load()), args=[Constant(value='--num_workers')], keywords=[keyword(arg='type', value=Name(id='int', ctx=Load())), keyword(arg='help', value=Constant(value='num_workers passed to torch.utils.data.DataLoader (default: 4)'))])), Expr(value=Call(func=Attribute(value=Name(id='group', ctx=Load()), attr='add_argument', ctx=Load()), args=[Constant(value='--download')], keywords=[keyword(arg='action', value=Constant(value='store_true')), keyword(arg='help', value=Constant(value='download dataset if not exist by calling self.initialize()'))])), Expr(value=Call(func=Attribute(value=Name(id='group', ctx=Load()), attr='add_argument', ctx=Load()), args=[Constant(value='--data_dir')], keywords=[keyword(arg='help', value=Constant(value='directory to contain datasets'))])), Return(value=Name(id='group', ctx=Load()))], decorator_list=[Name(id='classmethod', ctx=Load())], returns=Attribute(value=Name(id='argparse', ctx=Load()), attr='_ArgumentGroup', ctx=Load())), FunctionDef(name='__init__', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='batch_size', annotation=Name(id='int', ctx=Load())), arg(arg='valid_batch_size', annotation=Name(id='int', ctx=Load())), arg(arg='folder_path', annotation=Name(id='str', ctx=Load())), arg(arg='download', annotation=Name(id='bool', ctx=Load())), arg(arg='split_ratio', annotation=Name(id='float', ctx=Load())), arg(arg='num_workers', annotation=Name(id='int', ctx=Load())), arg(arg='loss_weights', annotation=BinOp(left=BinOp(left=Name(id='bool', ctx=Load()), op=BitOr(), right=Attribute(value=Name(id='np', ctx=Load()), attr='ndarray', ctx=Load())), op=BitOr(), right=Attribute(value=Name(id='torch', ctx=Load()), attr='Tensor', ctx=Load())))], kwonlyargs=[], kw_defaults=[], kwarg=arg(arg='kwargs'), defaults=[Constant(value=100), Constant(value=100), Constant(value=None), Constant(value=False), Constant(value=0.8), Constant(value=4), Constant(value=False)]), body=[Expr(value=Call(func=Attribute(value=Call(func=Name(id='super', ctx=Load()), args=[], keywords=[]), attr='__init__', ctx=Load()), args=[], keywords=[keyword(value=Name(id='kwargs', ctx=Load()))])), Assign(targets=[Subscript(value=Attribute(value=Name(id='self', ctx=Load()), attr='param_list', ctx=Load()), slice=Constant(value='dataset'), ctx=Store())], value=List(elts=[Constant(value='num_classes'), Constant(value='batch_size'), Constant(value='valid_batch_size'), Constant(value='folder_path'), Constant(value='num_workers')], ctx=Load())), If(test=UnaryOp(op=Not(), operand=Attribute(value=Name(id='self', ctx=Load()), attr='valid_set', ctx=Load())), body=[Expr(value=Call(func=Attribute(value=Subscript(value=Attribute(value=Name(id='self', ctx=Load()), attr='param_list', ctx=Load()), slice=Constant(value='dataset'), ctx=Load()), attr='append', ctx=Load()), args=[Constant(value='split_ratio')], keywords=[]))], orelse=[]), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='__batch_size', ctx=Store())], value=Name(id='batch_size', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='__valid_batch_size', ctx=Store())], value=Name(id='valid_batch_size', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='split_ratio', ctx=Store())], value=Name(id='split_ratio', ctx=Load())), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='num_workers', ctx=Store())], value=Name(id='num_workers', ctx=Load())), AnnAssign(target=Attribute(value=Name(id='self', ctx=Load()), attr='collate_fn', ctx=Store()), annotation=Subscript(value=Name(id='Callable', ctx=Load()), slice=Tuple(elts=[List(elts=[Subscript(value=Name(id='Iterable', ctx=Load()), slice=Attribute(value=Name(id='torch', ctx=Load()), attr='Tensor', ctx=Load()), ctx=Load())], ctx=Load()), Subscript(value=Name(id='Iterable', ctx=Load()), slice=Attribute(value=Name(id='torch', ctx=Load()), attr='Tensor', ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load()), value=Constant(value=None), simple=0), If(test=Compare(left=Name(id='folder_path', ctx=Load()), ops=[IsNot()], comparators=[Constant(value=None)]), body=[Assign(targets=[Name(id='folder_path', ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id='os', ctx=Load()), attr='path', ctx=Load()), attr='normpath', ctx=Load()), args=[Name(id='folder_path', ctx=Load())], keywords=[])), If(test=UnaryOp(op=Not(), operand=Call(func=Attribute(value=Attribute(value=Name(id='os', ctx=Load()), attr='path', ctx=Load()), attr='exists', ctx=Load()), args=[Name(id='folder_path', ctx=Load())], keywords=[])), body=[Expr(value=Call(func=Attribute(value=Name(id='os', ctx=Load()), attr='makedirs', ctx=Load()), args=[Name(id='folder_path', ctx=Load())], keywords=[]))], orelse=[])], orelse=[]), Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='folder_path', ctx=Store())], value=Name(id='folder_path', ctx=Load())), If(test=BoolOp(op=And(), values=[Name(id='download', ctx=Load()), UnaryOp(op=Not(), operand=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='check_files', ctx=Load()), args=[], keywords=[]))]), body=[Expr(value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='initialize', ctx=Load()), args=[], keywords=[]))], orelse=[]), Try(body=[Assign(targets=[Attribute(value=Name(id='self', ctx=Load()), attr='loader', ctx=Store())], value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='_get_loader_dict', ctx=Load()), args=[], keywords=[]))], handlers=[ExceptHandler(type=Name(id='Exception', ctx=Load()), body=[Expr(value=Call(func=Name(id='print', ctx=Load()), args=[JoinedStr(values=[Constant(value='Dataset Folder Path: '), FormattedValue(value=Attribute(value=Name(id='self', ctx=Load()), attr='folder_path', ctx=Load()), conversion=-1)])], keywords=[])), Raise()])], orelse=[], finalbody=[]), Match(subject=Name(id='loss_weights', ctx=Load()), cases=[match_case(pattern=MatchClass(cls=Name(id='bool', ctx=Load()), patterns=[], kwd_attrs=[], kwd_patterns=[]), body=[Assign(targets=[Name(id='loss_weights', ctx=Store())], value=IfExp(test=Name(id='loss_weights', ctx=Load()), body=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='get_loss_weights', ctx=Load()), args=[], keywords=[]), orelse=Constant(value=None)))]), match_case(pattern=MatchClass(cls=Attribute(value=Name(id='np', ctx=Load()), attr='ndarray', ctx=Load()), patterns=[], kwd_attrs=[], kwd_patterns=[]), body=[Assign(targets=[Name(id='loss_weights', ctx=Store())], value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id='torch', ctx=Load()), attr='from_numpy', ctx=Load()), args=[Name(id='loss_weights', ctx=Load())], keywords=[]), attr='to', ctx=Load()), args=[], keywords=[keyword(arg='device', value=Subscript(value=Name(id='env', ctx=Load()), slice=Constant(value='device'), ctx=Load()))]))]), match_case(pattern=MatchClass(cls=Attribute(value=Name(id='torch', ctx=Load()), attr='Tensor', ctx=Load()), patterns=[], kwd_attrs=[], kwd_patterns=[]), body=[Assign(targets=[Name(id='loss_weights', ctx=Store())], value=Call(func=Attribute(value=Name(id='loss_weights', ctx=Load()), attr='to', ctx=Load()), args=[], keywords=[keyword(arg='device', value=Subscript(value=Name(id='env', ctx=Load()), slice=Constant(value='device'), ctx=Load()))]))]), match_case(pattern=MatchAs(), body=[Raise(exc=Call(func=Name(id='TypeError', ctx=Load()), args=[Call(func=Name(id='type', ctx=Load()), args=[Name(id='loss_weights', ctx=Load())], keywords=[])], keywords=[]))])]), AnnAssign(target=Attribute(value=Name(id='self', ctx=Load()), attr='loss_weights', ctx=Store()), annotation=BinOp(left=Constant(value=None), op=BitOr(), right=Attribute(value=Name(id='torch', ctx=Load()), attr='Tensor', ctx=Load())), value=Name(id='loss_weights', ctx=Load()), simple=0)], decorator_list=[]), FunctionDef(name='_get_loader_dict', args=arguments(posonlyargs=[], args=[arg(arg='self')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Return(value=Dict(keys=[Constant(value='train'), Constant(value='valid')], values=[Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='get_dataloader', ctx=Load()), args=[], keywords=[keyword(arg='mode', value=Constant(value='train'))]), Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='get_dataloader', ctx=Load()), args=[], keywords=[keyword(arg='mode', value=Constant(value='valid'))])]))], decorator_list=[], returns=Subscript(value=Name(id='dict', ctx=Load()), slice=Tuple(elts=[Name(id='str', ctx=Load()), Attribute(value=Attribute(value=Attribute(value=Name(id='torch', ctx=Load()), attr='utils', ctx=Load()), attr='data', ctx=Load()), attr='DataLoader', ctx=Load())], ctx=Load()), ctx=Load())), FunctionDef(name='batch_size', args=arguments(posonlyargs=[], args=[arg(arg='self')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Return(value=IfExp(test=Compare(left=Attribute(value=Name(id='self', ctx=Load()), attr='__batch_size', ctx=Load()), ops=[GtE()], comparators=[Constant(value=0)]), body=Attribute(value=Name(id='self', ctx=Load()), attr='__batch_size', ctx=Load()), orelse=BinOp(left=UnaryOp(op=USub(), operand=Attribute(value=Name(id='self', ctx=Load()), attr='__batch_size', ctx=Load())), op=Mult(), right=Call(func=Name(id='max', ctx=Load()), args=[Constant(value=1), Subscript(value=Name(id='env', ctx=Load()), slice=Constant(value='num_gpus'), ctx=Load())], keywords=[]))))], decorator_list=[Attribute(value=Name(id='functools', ctx=Load()), attr='cached_property', ctx=Load())]), FunctionDef(name='valid_batch_size', args=arguments(posonlyargs=[], args=[arg(arg='self')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Return(value=IfExp(test=Compare(left=Attribute(value=Name(id='self', ctx=Load()), attr='__valid_batch_size', ctx=Load()), ops=[GtE()], comparators=[Constant(value=0)]), body=Attribute(value=Name(id='self', ctx=Load()), attr='__valid_batch_size', ctx=Load()), orelse=BinOp(left=UnaryOp(op=USub(), operand=Attribute(value=Name(id='self', ctx=Load()), attr='__valid_batch_size', ctx=Load())), op=Mult(), right=Call(func=Name(id='max', ctx=Load()), args=[Constant(value=1), Subscript(value=Name(id='env', ctx=Load()), slice=Constant(value='num_gpus'), ctx=Load())], keywords=[]))))], decorator_list=[Attribute(value=Name(id='functools', ctx=Load()), attr='cached_property', ctx=Load())]), FunctionDef(name='initialize', args=arguments(posonlyargs=[], args=[arg(arg='self')], vararg=arg(arg='args'), kwonlyargs=[], kw_defaults=[], kwarg=arg(arg='kwargs'), defaults=[]), body=[Expr(value=Constant(value=\"Initialize the dataset (download and extract) if it's not prepared yet\\n        (need overriding).\\n        \")), Raise(exc=Call(func=Name(id='NotImplementedError', ctx=Load()), args=[], keywords=[]))], decorator_list=[]), FunctionDef(name='check_files', args=arguments(posonlyargs=[], args=[arg(arg='self')], kwonlyargs=[], kw_defaults=[], kwarg=arg(arg='kwargs'), defaults=[]), body=[Expr(value=Constant(value='Check if the dataset files are prepared.\\n\\n        Args:\\n            **kwargs: Keyword arguments passed to :meth:`get_org_dataset`.\\n\\n        Returns:\\n            bool: Whether the dataset files are prepared.\\n        ')), Try(body=[Expr(value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='get_org_dataset', ctx=Load()), args=[], keywords=[keyword(arg='mode', value=Constant(value='train')), keyword(arg='transform', value=Constant(value=None)), keyword(value=Name(id='kwargs', ctx=Load()))])), If(test=Attribute(value=Name(id='self', ctx=Load()), attr='valid_set', ctx=Load()), body=[Expr(value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='get_org_dataset', ctx=Load()), args=[], keywords=[keyword(arg='mode', value=Constant(value='valid')), keyword(arg='transform', value=Constant(value=None)), keyword(value=Name(id='kwargs', ctx=Load()))]))], orelse=[]), Return(value=Constant(value=True))], handlers=[ExceptHandler(type=Name(id='Exception', ctx=Load()), body=[Return(value=Constant(value=False))])], orelse=[], finalbody=[])], decorator_list=[], returns=Name(id='bool', ctx=Load())), FunctionDef(name='get_transform', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='mode', annotation=Name(id='str', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value=\"Get dataset transform for mode.\\n\\n        Args:\\n            mode (str): Dataset mode (e.g., ``'train'`` or ``'valid'``).\\n\\n        Returns:\\n            ~collections.abc.Callable: A callable transform.\\n        \")), Expr(value=Constant(value=Ellipsis))], decorator_list=[Name(id='abstractmethod', ctx=Load())], returns=Name(id='Callable', ctx=Load())), FunctionDef(name='get_data', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='data')], kwonlyargs=[], kw_defaults=[], kwarg=arg(arg='kwargs'), defaults=[]), body=[Expr(value=Constant(value='Process data. Defaults to directly return :attr:`data`.\\n\\n        Args:\\n            data (Any): Unprocessed data.\\n            **kwargs: Keyword arguments to process data.\\n\\n        Returns:\\n            Any: Processed data.\\n        ')), Return(value=Name(id='data', ctx=Load()))], decorator_list=[]), FunctionDef(name='get_org_dataset', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='mode', annotation=Name(id='str', ctx=Load()))], kwonlyargs=[], kw_defaults=[], kwarg=arg(arg='kwargs'), defaults=[]), body=[Expr(value=Constant(value=\"Get original dataset that is not splitted.\\n\\n        Note:\\n            This is a wrapper and the specific implementation\\n            is in :meth:`_get_org_dataset`, which needs overriding.\\n\\n        Args:\\n            mode (str): Dataset mode (e.g., ``'train'`` or ``'valid'``).\\n            transform (~collections.abc.Callable):\\n                The transform applied on dataset.\\n                Defaults to :meth:`get_transform()`.\\n            **kwargs: Keyword arguments passed to :meth:`_get_org_dataset`.\\n\\n        Returns:\\n            torch.utils.data.Dataset: The original dataset.\\n\\n        See Also:\\n            :meth:`get_dataset`\\n        \")), If(test=Compare(left=Constant(value='transform'), ops=[NotIn()], comparators=[Call(func=Attribute(value=Name(id='kwargs', ctx=Load()), attr='keys', ctx=Load()), args=[], keywords=[])]), body=[Assign(targets=[Subscript(value=Name(id='kwargs', ctx=Load()), slice=Constant(value='transform'), ctx=Store())], value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='get_transform', ctx=Load()), args=[], keywords=[keyword(arg='mode', value=Name(id='mode', ctx=Load()))]))], orelse=[]), Return(value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='_get_org_dataset', ctx=Load()), args=[], keywords=[keyword(arg='mode', value=Name(id='mode', ctx=Load())), keyword(value=Name(id='kwargs', ctx=Load()))]))], decorator_list=[], returns=Attribute(value=Attribute(value=Attribute(value=Name(id='torch', ctx=Load()), attr='utils', ctx=Load()), attr='data', ctx=Load()), attr='Dataset', ctx=Load())), FunctionDef(name='_get_org_dataset', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='mode', annotation=Name(id='str', ctx=Load())), arg(arg='transform', annotation=BinOp(left=Name(id='Callable', ctx=Load()), op=BitOr(), right=Constant(value=None)))], kwonlyargs=[], kw_defaults=[], kwarg=arg(arg='kwargs'), defaults=[Constant(value=None)]), body=[Expr(value=Constant(value=Ellipsis))], decorator_list=[Name(id='abstractmethod', ctx=Load())], returns=Attribute(value=Attribute(value=Attribute(value=Name(id='torch', ctx=Load()), attr='utils', ctx=Load()), attr='data', ctx=Load()), attr='Dataset', ctx=Load())), FunctionDef(name='get_dataset', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='mode', annotation=Name(id='str', ctx=Load())), arg(arg='seed', annotation=Name(id='int', ctx=Load())), arg(arg='class_list', annotation=BinOp(left=BinOp(left=Constant(value=None), op=BitOr(), right=Name(id='int', ctx=Load())), op=BitOr(), right=Subscript(value=Name(id='list', ctx=Load()), slice=Name(id='int', ctx=Load()), ctx=Load())))], kwonlyargs=[], kw_defaults=[], kwarg=arg(arg='kwargs'), defaults=[Constant(value=None), Constant(value=None), Constant(value=None)]), body=[Expr(value=Constant(value=\"Get dataset. Call :meth:`split_dataset` to split the training set\\n        if :attr:`valid_set` is ``False``.\\n\\n        Args:\\n            mode (str): Dataset mode (e.g., ``'train'`` or ``'valid'``).\\n            seed (int): The random seed to split dataset\\n                using :any:`numpy.random.shuffle`.\\n                Defaults to ``env['data_seed']``.\\n            class_list (int | list[int]):\\n                The class list to pick. Defaults to ``None``.\\n            **kwargs: Keyword arguments passed to :meth:`get_org_dataset`.\\n\\n        Returns:\\n            torch.utils.data.Dataset: The original dataset.\\n        \")), Try(body=[If(test=BoolOp(op=Or(), values=[Attribute(value=Name(id='self', ctx=Load()), attr='valid_set', ctx=Load()), Compare(left=Name(id='mode', ctx=Load()), ops=[NotIn()], comparators=[List(elts=[Constant(value='train'), Constant(value='valid')], ctx=Load())])]), body=[Assign(targets=[Name(id='dataset', ctx=Store())], value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='get_org_dataset', ctx=Load()), args=[], keywords=[keyword(arg='mode', value=Name(id='mode', ctx=Load())), keyword(value=Name(id='kwargs', ctx=Load()))]))], orelse=[Assign(targets=[Name(id='dataset', ctx=Store())], value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='get_org_dataset', ctx=Load()), args=[], keywords=[keyword(arg='mode', value=Constant(value='train')), keyword(value=Name(id='kwargs', ctx=Load()))])), AnnAssign(target=Name(id='subset', ctx=Store()), annotation=Subscript(value=Name(id='dict', ctx=Load()), slice=Tuple(elts=[Name(id='str', ctx=Load()), Attribute(value=Attribute(value=Attribute(value=Name(id='torch', ctx=Load()), attr='utils', ctx=Load()), attr='data', ctx=Load()), attr='Subset', ctx=Load())], ctx=Load()), ctx=Load()), value=Dict(keys=[], values=[]), simple=1), Assign(targets=[Tuple(elts=[Subscript(value=Name(id='subset', ctx=Load()), slice=Constant(value='train'), ctx=Store()), Subscript(value=Name(id='subset', ctx=Load()), slice=Constant(value='valid'), ctx=Store())], ctx=Store())], value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='split_dataset', ctx=Load()), args=[Name(id='dataset', ctx=Load())], keywords=[keyword(arg='percent', value=Attribute(value=Name(id='self', ctx=Load()), attr='split_ratio', ctx=Load())), keyword(arg='seed', value=Name(id='seed', ctx=Load()))])), Assign(targets=[Name(id='dataset', ctx=Store())], value=Subscript(value=Name(id='subset', ctx=Load()), slice=Name(id='mode', ctx=Load()), ctx=Load()))])], handlers=[ExceptHandler(type=Name(id='RuntimeError', ctx=Load()), body=[Expr(value=Call(func=Name(id='print', ctx=Load()), args=[JoinedStr(values=[Constant(value='self.folder_path='), FormattedValue(value=Attribute(value=Name(id='self', ctx=Load()), attr='folder_path', ctx=Load()), conversion=114)])], keywords=[])), Raise()])], orelse=[], finalbody=[]), If(test=Compare(left=Name(id='class_list', ctx=Load()), ops=[IsNot()], comparators=[Constant(value=None)]), body=[Assign(targets=[Name(id='dataset', ctx=Store())], value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='get_class_subset', ctx=Load()), args=[], keywords=[keyword(arg='dataset', value=Name(id='dataset', ctx=Load())), keyword(arg='class_list', value=Name(id='class_list', ctx=Load()))]))], orelse=[]), Return(value=Name(id='dataset', ctx=Load()))], decorator_list=[]), FunctionDef(name='split_dataset', args=arguments(posonlyargs=[], args=[arg(arg='dataset', annotation=BinOp(left=Attribute(value=Attribute(value=Attribute(value=Name(id='torch', ctx=Load()), attr='utils', ctx=Load()), attr='data', ctx=Load()), attr='Dataset', ctx=Load()), op=BitOr(), right=Attribute(value=Attribute(value=Attribute(value=Name(id='torch', ctx=Load()), attr='utils', ctx=Load()), attr='data', ctx=Load()), attr='Subset', ctx=Load()))), arg(arg='length', annotation=Name(id='int', ctx=Load())), arg(arg='percent', annotation=Name(id='float', ctx=Load())), arg(arg='shuffle', annotation=Name(id='bool', ctx=Load())), arg(arg='seed', annotation=Name(id='int', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=None), Constant(value=None), Constant(value=True), Constant(value=None)]), body=[Expr(value=Constant(value=\"Split a dataset into two subsets.\\n\\n        Args:\\n            dataset (torch.utils.data.Dataset): The dataset to split.\\n            length (int): The length of the first subset.\\n                This argument cannot be used together with :attr:`percent`.\\n                If ``None``, use :attr:`percent` to calculate length instead.\\n                Defaults to ``None``.\\n            percent (float): The split ratio for the first subset.\\n                This argument cannot be used together with :attr:`length`.\\n                ``length = percent * len(dataset)``.\\n                Defaults to ``None``.\\n            shuffle (bool): Whether to shuffle the dataset.\\n                Defaults to ``True``.\\n            seed (bool): The random seed to split dataset\\n                using :any:`numpy.random.shuffle`.\\n                Defaults to ``env['data_seed']``.\\n\\n        Returns:\\n            (torch.utils.data.Subset, torch.utils.data.Subset):\\n                The two splitted subsets.\\n\\n        :Example:\\n            >>> from trojanzoo.utils.data import TensorListDataset\\n            >>> from trojanzoo.datasets import Dataset\\n            >>> import torch\\n            >>>\\n            >>> data = torch.ones(11, 3, 32, 32)\\n            >>> targets = list(range(11))\\n            >>> dataset = TensorListDataset(data, targets)\\n            >>> set1, set2 = Dataset.split_dataset(dataset, length=3)\\n            >>> len(set1), len(set2)\\n            (3, 8)\\n            >>> set3, set4 = split_dataset(dataset, percent=0.5)\\n            >>> len(set3), len(set4)\\n            (5, 6)\\n\\n        See Also:\\n            The implementation is in\\n            :func:`trojanzoo.utils.data.split_dataset`.\\n            The difference is that this method will set :attr:`seed`\\n            as ``env['data_seed']`` when it is ``None``.\\n        \")), Assign(targets=[Name(id='seed', ctx=Store())], value=IfExp(test=Compare(left=Name(id='seed', ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), body=Subscript(value=Name(id='env', ctx=Load()), slice=Constant(value='data_seed'), ctx=Load()), orelse=Name(id='seed', ctx=Load()))), Return(value=Call(func=Name(id='split_dataset', ctx=Load()), args=[Name(id='dataset', ctx=Load())], keywords=[keyword(arg='length', value=Name(id='length', ctx=Load())), keyword(arg='percent', value=Name(id='percent', ctx=Load())), keyword(arg='shuffle', value=Name(id='shuffle', ctx=Load())), keyword(arg='seed', value=Name(id='seed', ctx=Load()))]))], decorator_list=[Name(id='staticmethod', ctx=Load())]), FunctionDef(name='get_class_subset', args=arguments(posonlyargs=[], args=[arg(arg='dataset', annotation=Attribute(value=Attribute(value=Attribute(value=Name(id='torch', ctx=Load()), attr='utils', ctx=Load()), attr='data', ctx=Load()), attr='Dataset', ctx=Load())), arg(arg='class_list', annotation=BinOp(left=Name(id='int', ctx=Load()), op=BitOr(), right=Subscript(value=Name(id='list', ctx=Load()), slice=Name(id='int', ctx=Load()), ctx=Load())))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='Get a subset from dataset with certain classes.\\n\\n        Args:\\n            dataset (torch.utils.data.Dataset): The entire dataset.\\n            class_list (int | list[int]): The class list to pick.\\n\\n        Returns:\\n            torch.utils.data.Subset:\\n                The subset with labels in :attr:`class_list`.\\n\\n        :Example:\\n            >>> from trojanzoo.utils.data import TensorListDataset\\n            >>> from trojanzoo.utils.data import get_class_subset\\n            >>> import torch\\n            >>>\\n            >>> data = torch.ones(11, 3, 32, 32)\\n            >>> targets = list(range(11))\\n            >>> dataset = TensorListDataset(data, targets)\\n            >>> subset = get_class_subset(dataset, class_list=[2, 3])\\n            >>> len(subset)\\n            2\\n\\n        See Also:\\n            The implementation is in\\n            :func:`trojanzoo.utils.data.get_class_subset`.\\n        ')), Return(value=Call(func=Name(id='get_class_subset', ctx=Load()), args=[], keywords=[keyword(arg='dataset', value=Name(id='dataset', ctx=Load())), keyword(arg='class_list', value=Name(id='class_list', ctx=Load()))]))], decorator_list=[Name(id='staticmethod', ctx=Load())], returns=Attribute(value=Attribute(value=Attribute(value=Name(id='torch', ctx=Load()), attr='utils', ctx=Load()), attr='data', ctx=Load()), attr='Subset', ctx=Load())), FunctionDef(name='get_dataloader', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='mode', annotation=Name(id='str', ctx=Load())), arg(arg='dataset', annotation=Attribute(value=Attribute(value=Attribute(value=Name(id='torch', ctx=Load()), attr='utils', ctx=Load()), attr='data', ctx=Load()), attr='Dataset', ctx=Load())), arg(arg='batch_size', annotation=Name(id='int', ctx=Load())), arg(arg='shuffle', annotation=Name(id='bool', ctx=Load())), arg(arg='num_workers', annotation=Name(id='int', ctx=Load())), arg(arg='pin_memory', annotation=Name(id='bool', ctx=Load())), arg(arg='drop_last', annotation=Name(id='bool', ctx=Load())), arg(arg='collate_fn', annotation=Name(id='Callable', ctx=Load()))], kwonlyargs=[], kw_defaults=[], kwarg=arg(arg='kwargs'), defaults=[Constant(value=None), Constant(value=None), Constant(value=None), Constant(value=None), Constant(value=None), Constant(value=True), Constant(value=False), Constant(value=None)]), body=[Expr(value=Constant(value=\"Get dataloader. Call :meth:`get_dataset` if :attr:`dataset` is not provided.\\n\\n        Args:\\n            mode (str): Dataset mode (e.g., ``'train'`` or ``'valid'``).\\n            dataset (torch.utils.data.Dataset): The pytorch dataset.\\n            batch_size (int):\\n                Defaults to :attr:`self.batch_size` for ``'train'`` mode\\n                and :attr:`self.valid_batch_size` for ``'valid'`` mode.\\n            shuffle (bool): Whether to shuffle.\\n                Defaults to ``True`` for ``'train'`` mode\\n                and ``False`` for ``'valid'`` mode.\\n            num_workers (int): Number of workers for dataloader.\\n                Defaults to :attr:`self.num_workers`.\\n            pin_memory (bool): Whether to use pin memory.\\n                Defaults to ``True`` if there is any GPU available.\\n            drop_last (bool): Whether drop the last batch if not full size.\\n                Defaults to ``False``.\\n            collate_fn (~collections.abc.Callable):\\n                Passed to :any:`torch.utils.data.DataLoader`.\\n            **kwargs: Keyword arguments passed to :meth:`get_dataset`\\n                if :attr:`dataset` is not provided.\\n\\n        Returns:\\n            torch.utils.data.DataLoader: The pytorch dataloader.\\n        \")), If(test=Compare(left=Name(id='batch_size', ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), body=[Match(subject=Name(id='mode', ctx=Load()), cases=[match_case(pattern=MatchValue(value=Constant(value='valid')), body=[Assign(targets=[Name(id='batch_size', ctx=Store())], value=Attribute(value=Name(id='self', ctx=Load()), attr='valid_batch_size', ctx=Load()))]), match_case(pattern=MatchAs(), body=[Assign(targets=[Name(id='batch_size', ctx=Store())], value=Attribute(value=Name(id='self', ctx=Load()), attr='batch_size', ctx=Load()))])])], orelse=[]), If(test=Compare(left=Name(id='shuffle', ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), body=[Assign(targets=[Name(id='shuffle', ctx=Store())], value=Compare(left=Name(id='mode', ctx=Load()), ops=[Eq()], comparators=[Constant(value='train')]))], orelse=[]), If(test=Compare(left=Name(id='num_workers', ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), body=[Assign(targets=[Name(id='num_workers', ctx=Store())], value=Attribute(value=Name(id='self', ctx=Load()), attr='num_workers', ctx=Load()))], orelse=[]), If(test=Compare(left=Name(id='dataset', ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), body=[Assign(targets=[Name(id='dataset', ctx=Store())], value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='get_dataset', ctx=Load()), args=[], keywords=[keyword(arg='mode', value=Name(id='mode', ctx=Load())), keyword(value=Name(id='kwargs', ctx=Load()))]))], orelse=[]), Assign(targets=[Name(id='pin_memory', ctx=Store())], value=BoolOp(op=And(), values=[Name(id='pin_memory', ctx=Load()), Subscript(value=Name(id='env', ctx=Load()), slice=Constant(value='num_gpus'), ctx=Load())])), Assign(targets=[Name(id='collate_fn', ctx=Store())], value=BoolOp(op=Or(), values=[Name(id='collate_fn', ctx=Load()), Attribute(value=Name(id='self', ctx=Load()), attr='collate_fn', ctx=Load())])), Return(value=Call(func=Attribute(value=Attribute(value=Attribute(value=Name(id='torch', ctx=Load()), attr='utils', ctx=Load()), attr='data', ctx=Load()), attr='DataLoader', ctx=Load()), args=[Name(id='dataset', ctx=Load())], keywords=[keyword(arg='batch_size', value=Name(id='batch_size', ctx=Load())), keyword(arg='shuffle', value=Name(id='shuffle', ctx=Load())), keyword(arg='num_workers', value=Name(id='num_workers', ctx=Load())), keyword(arg='pin_memory', value=Name(id='pin_memory', ctx=Load())), keyword(arg='drop_last', value=Name(id='drop_last', ctx=Load())), keyword(arg='collate_fn', value=Name(id='collate_fn', ctx=Load()))]))], decorator_list=[], returns=Attribute(value=Attribute(value=Attribute(value=Name(id='torch', ctx=Load()), attr='utils', ctx=Load()), attr='data', ctx=Load()), attr='DataLoader', ctx=Load())), FunctionDef(name='get_loss_weights', args=arguments(posonlyargs=[], args=[arg(arg='self'), arg(arg='file_path', annotation=Name(id='str', ctx=Load())), arg(arg='verbose', annotation=Name(id='bool', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=None), Constant(value=True)]), body=[Expr(value=Constant(value='Calculate :attr:`loss_weights` as reciprocal of data size of each class\\n        (to mitigate data imbalance).\\n\\n        Args:\\n            file_path (str):\\n                | The file path of saved weights file.\\n                | If exist, just load the file and return;\\n                | else, calculate the weights, save and return.\\n                | Defaults to ``{folder_path}/loss_weights.npy``\\n            verbose (bool): Whether to print verbose information.\\n                Defaults to ``True``.\\n\\n        Returns:\\n            torch.Tensor: The tensor of loss weights w.r.t. each class.\\n        ')), Assign(targets=[Name(id='file_path', ctx=Store())], value=IfExp(test=Compare(left=Name(id='file_path', ctx=Load()), ops=[IsNot()], comparators=[Constant(value=None)]), body=Name(id='file_path', ctx=Load()), orelse=Call(func=Attribute(value=Attribute(value=Name(id='os', ctx=Load()), attr='path', ctx=Load()), attr='join', ctx=Load()), args=[Attribute(value=Name(id='self', ctx=Load()), attr='folder_path', ctx=Load()), Constant(value='loss_weights.npy')], keywords=[]))), If(test=Call(func=Attribute(value=Attribute(value=Name(id='os', ctx=Load()), attr='path', ctx=Load()), attr='exists', ctx=Load()), args=[Name(id='file_path', ctx=Load())], keywords=[]), body=[Assign(targets=[Name(id='loss_weights', ctx=Store())], value=Call(func=Attribute(value=Name(id='np', ctx=Load()), attr='load', ctx=Load()), args=[Name(id='file_path', ctx=Load())], keywords=[]))], orelse=[If(test=Name(id='verbose', ctx=Load()), body=[Expr(value=Call(func=Name(id='print', ctx=Load()), args=[Constant(value='Calculating Loss Weights')], keywords=[]))], orelse=[]), Assign(targets=[Name(id='dataset', ctx=Store())], value=Call(func=Attribute(value=Name(id='self', ctx=Load()), attr='get_dataset', ctx=Load()), args=[Constant(value='train')], keywords=[keyword(arg='transform', value=Constant(value=None))])), Assign(targets=[Name(id='targets', ctx=Store())], value=Call(func=Attribute(value=Name(id='np', ctx=Load()), attr='array', ctx=Load()), args=[Subscript(value=Call(func=Name(id='list', ctx=Load()), args=[Call(func=Name(id='zip', ctx=Load()), args=[Starred(value=Name(id='dataset', ctx=Load()), ctx=Load())], keywords=[])], keywords=[]), slice=Constant(value=1), ctx=Load())], keywords=[])), Assign(targets=[Name(id='loss_weights', ctx=Store())], value=Call(func=Attribute(value=Name(id='np', ctx=Load()), attr='reciprocal', ctx=Load()), args=[Call(func=Attribute(value=Call(func=Attribute(value=Name(id='np', ctx=Load()), attr='bincount', ctx=Load()), args=[Name(id='targets', ctx=Load())], keywords=[]), attr='astype', ctx=Load()), args=[Name(id='float', ctx=Load())], keywords=[])], keywords=[])), Assert(test=Compare(left=Call(func=Name(id='len', ctx=Load()), args=[Name(id='loss_weights', ctx=Load())], keywords=[]), ops=[Eq()], comparators=[Attribute(value=Name(id='self', ctx=Load()), attr='num_classes', ctx=Load())])), Expr(value=Call(func=Attribute(value=Name(id='np', ctx=Load()), attr='save', ctx=Load()), args=[Name(id='file_path', ctx=Load()), Name(id='loss_weights', ctx=Load())], keywords=[])), If(test=Name(id='verbose', ctx=Load()), body=[Expr(value=Call(func=Name(id='print', ctx=Load()), args=[Constant(value='Loss Weights Saved at '), Name(id='file_path', ctx=Load())], keywords=[]))], orelse=[])]), Return(value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id='torch', ctx=Load()), attr='from_numpy', ctx=Load()), args=[Name(id='loss_weights', ctx=Load())], keywords=[]), attr='to', ctx=Load()), args=[], keywords=[keyword(arg='device', value=Subscript(value=Name(id='env', ctx=Load()), slice=Constant(value='device'), ctx=Load())), keyword(arg='dtype', value=Attribute(value=Name(id='torch', ctx=Load()), attr='float', ctx=Load()))]))], decorator_list=[], returns=Attribute(value=Name(id='torch', ctx=Load()), attr='Tensor', ctx=Load()))], decorator_list=[]), FunctionDef(name='add_argument', args=arguments(posonlyargs=[], args=[arg(arg='parser', annotation=Attribute(value=Name(id='argparse', ctx=Load()), attr='ArgumentParser', ctx=Load())), arg(arg='dataset_name', annotation=Name(id='str', ctx=Load())), arg(arg='dataset', annotation=BinOp(left=Name(id='str', ctx=Load()), op=BitOr(), right=Name(id='Dataset', ctx=Load()))), arg(arg='config', annotation=Name(id='Config', ctx=Load())), arg(arg='class_dict', annotation=Subscript(value=Name(id='dict', ctx=Load()), slice=Tuple(elts=[Name(id='str', ctx=Load()), Subscript(value=Name(id='type', ctx=Load()), slice=Name(id='Dataset', ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=None), Constant(value=None), Name(id='config', ctx=Load()), Dict(keys=[], values=[])]), body=[Expr(value=Constant(value='\\n    | Add dataset arguments to argument parser.\\n    | For specific arguments implementation, see :meth:`Dataset.add_argument()`.\\n\\n    Args:\\n        parser (argparse.ArgumentParser): The parser to add arguments.\\n        dataset_name (str): The dataset name.\\n        dataset (str | Dataset): Dataset instance or dataset name\\n            (as the alias of `dataset_name`).\\n        config (Config): The default parameter config,\\n            which contains the default dataset name if not provided.\\n        class_dict (dict[str, type[Dataset]]):\\n            Map from dataset name to dataset class.\\n            Defaults to ``{}``.\\n    ')), Assign(targets=[Name(id='dataset_name', ctx=Store())], value=Call(func=Name(id='get_name', ctx=Load()), args=[], keywords=[keyword(arg='name', value=Name(id='dataset_name', ctx=Load())), keyword(arg='module', value=Name(id='dataset', ctx=Load())), keyword(arg='arg_list', value=List(elts=[Constant(value='-d'), Constant(value='--dataset')], ctx=Load()))])), Assign(targets=[Name(id='dataset_name', ctx=Store())], value=IfExp(test=Compare(left=Name(id='dataset_name', ctx=Load()), ops=[IsNot()], comparators=[Constant(value=None)]), body=Name(id='dataset_name', ctx=Load()), orelse=Subscript(value=Subscript(value=Attribute(value=Name(id='config', ctx=Load()), attr='full_config', ctx=Load()), slice=Constant(value='dataset'), ctx=Load()), slice=Constant(value='default_dataset'), ctx=Load()))), Assign(targets=[Name(id='group', ctx=Store())], value=Call(func=Attribute(value=Name(id='parser', ctx=Load()), attr='add_argument_group', ctx=Load()), args=[Call(func=Attribute(value=Constant(value='{yellow}dataset{reset}'), attr='format', ctx=Load()), args=[], keywords=[keyword(value=Name(id='ansi', ctx=Load()))])], keywords=[keyword(arg='description', value=Name(id='dataset_name', ctx=Load()))])), Try(body=[Assign(targets=[Name(id='DatasetType', ctx=Store())], value=Subscript(value=Name(id='class_dict', ctx=Load()), slice=Name(id='dataset_name', ctx=Load()), ctx=Load()))], handlers=[ExceptHandler(type=Name(id='KeyError', ctx=Load()), body=[Expr(value=Call(func=Name(id='print', ctx=Load()), args=[JoinedStr(values=[FormattedValue(value=Name(id='dataset_name', ctx=Load()), conversion=-1), Constant(value=' not in \\n'), FormattedValue(value=Call(func=Name(id='list', ctx=Load()), args=[Call(func=Attribute(value=Name(id='class_dict', ctx=Load()), attr='keys', ctx=Load()), args=[], keywords=[])], keywords=[]), conversion=-1)])], keywords=[])), Raise()])], orelse=[], finalbody=[]), Return(value=Call(func=Attribute(value=Name(id='DatasetType', ctx=Load()), attr='add_argument', ctx=Load()), args=[Name(id='group', ctx=Load())], keywords=[]))], decorator_list=[], returns=Attribute(value=Name(id='argparse', ctx=Load()), attr='_ArgumentGroup', ctx=Load())), FunctionDef(name='create', args=arguments(posonlyargs=[], args=[arg(arg='dataset_name', annotation=Name(id='str', ctx=Load())), arg(arg='dataset', annotation=Name(id='str', ctx=Load())), arg(arg='config', annotation=Name(id='Config', ctx=Load())), arg(arg='class_dict', annotation=Subscript(value=Name(id='dict', ctx=Load()), slice=Tuple(elts=[Name(id='str', ctx=Load()), Subscript(value=Name(id='type', ctx=Load()), slice=Name(id='Dataset', ctx=Load()), ctx=Load())], ctx=Load()), ctx=Load()))], kwonlyargs=[], kw_defaults=[], kwarg=arg(arg='kwargs'), defaults=[Constant(value=None), Constant(value=None), Name(id='config', ctx=Load()), Dict(keys=[], values=[])]), body=[Expr(value=Constant(value=\"\\n    | Create a dataset instance.\\n    | For arguments not included in :attr:`kwargs`,\\n      use the default values in :attr:`config`.\\n    | The default value of :attr:`folder_path` is\\n      ``'{data_dir}/{data_type}/{name}'``.\\n    | For dataset implementation, see :class:`Dataset`.\\n\\n    Args:\\n        dataset_name (str): The dataset name.\\n        dataset (str): The alias of `dataset_name`.\\n        config (Config): The default parameter config.\\n        class_dict (dict[str, type[Dataset]]):\\n            Map from dataset name to dataset class.\\n            Defaults to ``{}``.\\n        **kwargs: Keyword arguments\\n            passed to dataset init method.\\n\\n    Returns:\\n        Dataset: Dataset instance.\\n    \")), Assign(targets=[Name(id='dataset_name', ctx=Store())], value=Call(func=Name(id='get_name', ctx=Load()), args=[], keywords=[keyword(arg='name', value=Name(id='dataset_name', ctx=Load())), keyword(arg='module', value=Name(id='dataset', ctx=Load())), keyword(arg='arg_list', value=List(elts=[Constant(value='-d'), Constant(value='--dataset')], ctx=Load()))])), Assign(targets=[Name(id='dataset_name', ctx=Store())], value=IfExp(test=Compare(left=Name(id='dataset_name', ctx=Load()), ops=[IsNot()], comparators=[Constant(value=None)]), body=Name(id='dataset_name', ctx=Load()), orelse=Subscript(value=Subscript(value=Attribute(value=Name(id='config', ctx=Load()), attr='full_config', ctx=Load()), slice=Constant(value='dataset'), ctx=Load()), slice=Constant(value='default_dataset'), ctx=Load()))), Assign(targets=[Name(id='result', ctx=Store())], value=Call(func=Attribute(value=Subscript(value=Call(func=Attribute(value=Name(id='config', ctx=Load()), attr='get_config', ctx=Load()), args=[], keywords=[keyword(arg='dataset_name', value=Name(id='dataset_name', ctx=Load()))]), slice=Constant(value='dataset'), ctx=Load()), attr='update', ctx=Load()), args=[Name(id='kwargs', ctx=Load())], keywords=[])), Try(body=[Assign(targets=[Name(id='DatasetType', ctx=Store())], value=Subscript(value=Name(id='class_dict', ctx=Load()), slice=Name(id='dataset_name', ctx=Load()), ctx=Load()))], handlers=[ExceptHandler(type=Name(id='KeyError', ctx=Load()), body=[Expr(value=Call(func=Name(id='print', ctx=Load()), args=[JoinedStr(values=[FormattedValue(value=Name(id='dataset_name', ctx=Load()), conversion=-1), Constant(value=' not in \\n'), FormattedValue(value=Call(func=Name(id='list', ctx=Load()), args=[Call(func=Attribute(value=Name(id='class_dict', ctx=Load()), attr='keys', ctx=Load()), args=[], keywords=[])], keywords=[]), conversion=-1)])], keywords=[])), Raise()])], orelse=[], finalbody=[]), If(test=Compare(left=Constant(value='folder_path'), ops=[NotIn()], comparators=[Call(func=Attribute(value=Name(id='result', ctx=Load()), attr='keys', ctx=Load()), args=[], keywords=[])]), body=[Assign(targets=[Subscript(value=Name(id='result', ctx=Load()), slice=Constant(value='folder_path'), ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id='os', ctx=Load()), attr='path', ctx=Load()), attr='join', ctx=Load()), args=[Subscript(value=Name(id='result', ctx=Load()), slice=Constant(value='data_dir'), ctx=Load()), Attribute(value=Name(id='DatasetType', ctx=Load()), attr='data_type', ctx=Load()), Attribute(value=Name(id='DatasetType', ctx=Load()), attr='name', ctx=Load())], keywords=[]))], orelse=[]), Return(value=Call(func=Name(id='DatasetType', ctx=Load()), args=[], keywords=[keyword(value=Name(id='result', ctx=Load()))]))], decorator_list=[], returns=Name(id='Dataset', ctx=Load()))], type_ignores=[])"